{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 :  Flight Delay Forecasting\n",
    "\n",
    "- **Machine Learning, Innopolis University (Fall semester 2021)**\n",
    "- **By Mohamed Gamal Elbayoumi**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import metrics\n",
    "\n",
    "plt.rcParams[\"patch.force_edgecolor\"] = True\n",
    "plt.style.use('fivethirtyeight')\n",
    "mpl.rc('patch', edgecolor = 'dimgray', linewidth=1)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('flight_delay.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exploratory data analysis (EDA)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get necessary details about dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show unique airports in dataset\n",
    "print(\"Number of depature airports: {}\".format(len(df['Depature Airport'].unique())))\n",
    "print(\"Number of destination airports: {}\".format(len(df['Destination Airport'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking for missing values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observe :** Dataset have no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any duplicates?\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete these duplicate\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical data into numerical values\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# one-hot-encode categorical features\n",
    "'''\n",
    "def ohe_new_features(df, features_name, encoder):\n",
    "    new_feats = encoder.transform(df[features_name])\n",
    "    # create dataframe from encoded features with named columns\n",
    "    new_cols = pd.DataFrame(new_feats, dtype=int, columns=encoder.get_feature_names(features_name))\n",
    "    new_df = pd.concat([df, new_cols], axis=1)    \n",
    "    new_df.drop(features_name, axis=1, inplace=True)\n",
    "    return new_df\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "cat_features = ['Depature Airport', 'Destination Airport']\n",
    "encoder.fit(df[cat_features])\n",
    "df = ohe_new_features(df, cat_features, encoder)\n",
    "df.head()\n",
    "'''\n",
    "encoder = LabelEncoder()\n",
    "df['Depature Airport'] = encoder.fit_transform(df['Depature Airport'])\n",
    "df['Destination Airport'] = encoder.fit_transform(df['Destination Airport'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.get_dummies(df, columns=['Depature Airport', 'Destination Airport'])\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting depature time & arrival time from object to a sutaible format\n",
    "df['Scheduled depature time'] = pd.to_datetime(df['Scheduled depature time'],format='%Y-%m-%d %H:%M:%S')\n",
    "df['Scheduled arrival time']  = pd.to_datetime(df['Scheduled arrival time'],format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding new feature 'flight_duration'\n",
    "flight_duration = df['Scheduled arrival time']-df['Scheduled depature time']\n",
    "# Converting duration to be in hour and add it to data frame\n",
    "flight_duration = flight_duration.dt.total_seconds()/3600\n",
    "df['flight_duration'] = flight_duration\n",
    "# Modify Daley feature to be in hour also, so the distances between values not far when bulding the model\n",
    "df['Delay']=df['Delay']/60\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting new features from Scheduled depature time column\n",
    "df['year_dep']=df['Scheduled depature time'].dt.year \n",
    "df['month_dep']=df['Scheduled depature time'].dt.month \n",
    "df['day_dep']=df['Scheduled depature time'].dt.day\n",
    "df['dayofweek_dep']=df['Scheduled depature time'].dt.dayofweek  \n",
    "df['hour_dep'] = df['Scheduled depature time'].dt.hour \n",
    "df['minute_dep'] = df['Scheduled depature time'].dt.minute\n",
    "\n",
    "# Extracting new features from Scheduled arrival time column\n",
    "df['year_arr']=df['Scheduled arrival time'].dt.year \n",
    "df['month_arr']=df['Scheduled arrival time'].dt.month \n",
    "df['day_arr']=df['Scheduled arrival time'].dt.day\n",
    "df['dayofweek_arr']=df['Scheduled arrival time'].dt.dayofweek  \n",
    "df['hour_arr'] = df['Scheduled arrival time'].dt.hour \n",
    "df['minute_arr'] = df['Scheduled arrival time'].dt.minute\n",
    "\n",
    "df = df.drop(['Scheduled depature time', 'Scheduled arrival time'], axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Detection & Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buliding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train & test data depends on year's value\n",
    "df_train = df[df['year_dep'] <= 2017]\n",
    "df_test  = df[df['year_dep'] == 2018]\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train    = df_train.drop('Delay', axis = 1)\n",
    "X_train_fd = df_train['flight_duration']\n",
    "y_train    = df_train['Delay']\n",
    "\n",
    "X_test     = df_test.drop('Delay', axis = 1)\n",
    "X_test_fd  = df_test['flight_duration']\n",
    "y_test     = df_test['Delay']\n",
    "\n",
    "# Reshape data because it contains a single sample\n",
    "X_train_fd = X_train_fd.values.reshape(-1, 1)\n",
    "X_test_fd  = X_test_fd.values.reshape(-1,1)\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scale features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After trying other scalers this one is the best\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler = RobustScaler()\n",
    "# scale x with one feature\n",
    "scaler.fit(X_train_fd)\n",
    "X_train_fd = scaler.transform(X_train_fd)\n",
    "X_test_fd = scaler.transform(X_test_fd)\n",
    "# scale x with one feature\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**simple linear regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train_fd, y_train)\n",
    "\n",
    "print(f\"Model intercept : {regressor.intercept_}\")\n",
    "print(f\"Model coefficient : {regressor.coef_}\")\n",
    "\n",
    "y_pred = regressor.predict(X_test_fd)\n",
    "eval_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model perfomence metrics\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In practice, this model tends to underestimate the large delays, which can be seen in the following figure:\n",
    "tips = pd.DataFrame()\n",
    "tips[\"prediction\"] = pd.Series([float(s) for s in y_pred]) \n",
    "tips[\"original_data\"] = pd.Series([float(s) for s in y_test]) \n",
    "\n",
    "sns.jointplot(data=tips, x=\"original_data\", y=\"prediction\", size = 6, ratio = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**multiple linear regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "print(f\"Model intercept : {regressor.intercept_}\")\n",
    "print(f\"Model coefficients : {regressor.coef_}\")\n",
    "\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips = pd.DataFrame()\n",
    "tips[\"prediction\"] = pd.Series([float(s) for s in y_pred]) \n",
    "tips[\"original_data\"] = pd.Series([float(s) for s in y_test]) \n",
    "\n",
    "sns.jointplot(data=tips, x=\"original_data\", y=\"prediction\", size = 6, ratio = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial regression\n",
    "Now I'll extend the previous fit by using a polynomial rather than a linear function:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**simple**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = PolynomialFeatures(degree=3)\n",
    "X_train_p = p.fit_transform(X_train_fd)\n",
    "reg = LinearRegression()\n",
    "y_train_ = reg.fit(X_train_p, y_train)\n",
    "\n",
    "# The coefficients\n",
    "print ('Coefficients: ', reg.coef_)\n",
    "print ('Intercept: ',reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_p = p.fit_transform(X_test_fd)\n",
    "prediction = reg.predict(X_test_p)\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, prediction))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, prediction))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, prediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multiple features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2)\n",
    "X_train_p = poly.fit_transform(X_train)\n",
    "reg = LinearRegression()\n",
    "y_train_ = reg.fit(X_train_p, y_train)\n",
    "\n",
    "# The coefficients\n",
    "print ('Coefficients: ', reg.coef_)\n",
    "print ('Intercept: ',reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
